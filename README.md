# Udacity Data Engineering Nanodegree
Learn to design data models, build data warehouses and data lakes, automate data pipelines, and work with massive datasets.


## Part 1: Data Modeling
Learn to create relational and NoSQL data models to fit the diverse needs of data consumers. Use ETL to build databases in PostgreSQL and Apache Cassandra.
<br>[**p1: Data Modeling with Postgres**]()
<br>[**p2: Data Modeling with Apache Cassandra**]()


## Part 2: Cloud Data Warehouses
Sharpen your data warehousing skills and deepen your understanding of data infrastructure. Create cloud-based data warehouses on Amazon Web Services (AWS).
<br>[**p3: Data Warehouse**]()


## Part 3: Data Lakes with Spark
Understand the big data ecosystem and how to use Spark to work with massive datasets. Store big data in a data lake and query it with Spark.
<br>[**p4: Data Lake**]()


## Part 4: Data Pipelines with Airflow
Schedule, automate, and monitor data pipelines using Apache Airflow. Run data quality checks, track data lineage, and work with data pipelines in production.
[<br>**p5: Data Pipelines**]()


## Final Project:
Combine what you've learned throughout the program to build your own data engineering portfolio project.
<br>[**p6: Capstone Project**]()
