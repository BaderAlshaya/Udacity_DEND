# Project 1: Data Modeling with Postgres


## Introduction
A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

They'd like us to create a Postgres database with tables designed to optimize queries on song play analysis. Our role is to create a database schema and ETL pipeline for this analysis. You'll be able to test your database and ETL pipeline by running queries given to you by the analytics team from Sparkify and compare our results with their expected results.
<br><br>


## Project Description
**Requirements:**
- We collect the data for user activity from a music streaming app called **Sparkify** in `JSON` file format.
- We creat a **Relational Database** to store the data using `PostgreSQL`. 
- We define **Fact** and **Dimension** tables for a **Star Schema** with a particular analytic focus. 
- We build an **ETL Pipeline** to transfer the date into these tables using `Python` and `SQL`.
- We optimize queries and understand what songs users are listening to.
- We finally test the database by comparing their given expected results with our own query results.
<br>


**Files:**
- `create_tables.py`: (Python) Set up the `sparkifydb` database and creates the tables.
- `sql_queries.py`: (Python) Specify insertion query template and initialize SQL queries to create and drope tables.
- `etl.py`: (Python) Read and transfer song_data and log_data.
- `etl.ipynb`: (Jupyter Notebook) Analyse dataset before loading it to the database.
- `test.ipynb`: (Jupyter Notebook) Test loaded data against expected data to validate the results.
<br>


**Data:**
- Song Dataset: 

Each song file is in `JSON` file format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.
<br>**For instance:** `song_data/A/A/B/TRAABJL12903CDCF1A.json` looks like:

    {"num_songs": 1, 
    "artist_id": "ARJIE2Y1187B994AB7", 
    "artist_latitude": null, 
    "artist_longitude": null,
    "artist_location": "", 
    "artist_name": "Line Renaud", 
    "song_id": "SOUPIRU12A6D4FA1E1", 
    "title": "Der Kleine Dompfaff", 
    "duration": 152.92036, 
    "year": 0}

- Log Dataset:

Each log file is in `JSON` file format generated by an event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations. The files are partitioned by year and month. 
<br>**For instance:** `log_data/2018/11/2018-11-10-events.json` looks like:

    {"artist":"Hoobastank",
    "auth":"Logged In",
    "firstName":"Cierra",
    "gender":"F",
    "itemInSession":0,
    "lastName":"Finley",
    "length":241.3971,
    "level":"free",
    "location":"Richmond, VA",
    "method":"PUT",
    "page":"NextSong",
    "registration":1541013292796.0,
    "sessionId":132,
    "song":"Say The Same",
    "status":200,
    "ts":1541808927796,
    "userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.77.4 (KHTML, like Gecko) Version\/7.0.5 Safari\/537.77.4\"",
    "userId":"96"}
<br>


**Database Schema Design:**

<br><br>


## Build
<br><br>


## Run
<br><br>


## Test
<br><br>


- Discuss the purpose of this database in the context of the startup, Sparkify, and their analytical goals.
- State and justify your database schema design and ETL pipeline.
- [Optional] Provide example queries and results for song play analysis.

